{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor to load your documents\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(filepath):\n",
    "    positive_path = os.path.join(filepath, 'pos')\n",
    "    negative_path = os.path.join(filepath, 'neg')\n",
    "    pos_label = 1\n",
    "    neg_label = 0\n",
    "    dataset = []\n",
    "    \n",
    "    for filename in glob.glob(os.path.join(positive_path, '*.txt')):\n",
    "        with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "            dataset.append((pos_label, f.read()))\n",
    "\n",
    "    for filename in glob.glob(os.path.join(negative_path, '*.txt')):\n",
    "        with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "            dataset.append((neg_label, f.read()))\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  \"Father of the Pride was the best new show to hit television since Family Guy. It was yet another masterpiece from the talented people at Dreamworks Animation. Like The Simpsons, the show centers around a nuclear family (of white lions, in this case). It also contains many memorable supporting characters including Roger the surly orangutan, Vincent the Italian-American flamingo, the eccentric white tigers Blake and Victoria, the faux patriotic Snout Brothers and Chutney the elephant. The other stars of the show are the Sigfreid and Roy. They are incredibly eccentric and do everything in a grandiose manner, making the most mundane activities entertaining. The combination of cute animal characters with very adult dialog and controversial issues (drugs, prejudice, etc) is the source of the program's brilliance.<br /><br />The blame for this show's failure lies with NBC. They opted to broadcast the episodes in no particular order (perhaps being influenced by which guest stars they could promote) rather than the more logical production order. Several times, the show was preempted for an extra half-hour of such dreck as The Biggest Loser (as if 60 minutes of that was not enough)! It is indeed an ill omen for the future of television as art if an original and daring show like this fails while Fear Factor and American Idol dominate.<br /><br />Luckily, the complete series was released on DVD and the show now has an opportunity to gain a larger following. 10/10\"),\n",
       " (1,\n",
       "  \"I have never danced flamenco before, but somehow I feel like this movie was perfect. The colors, how blatant the dances were, the gypsies, and the rivals all put together made a movie that seemed to have ended too soon. I have seen other Carlos Saura movies and I agree that this film may be his best production. I feel that the best characteristics of his past films were put together and aligned to make Iberia. I appreciate the use of mirrors in revealing the activity going on behind the cameras. While watching this movie I felt like I was sitting in a small restaurant in Madrid, comfortably watching the dancers bang on a wooden plank over a delicious fruit cocktail. For me, this movie fit like a glove. I don't know how I will be able to get a copy of this film in the US in the next few years. I recommend this movie to anyone who is attracted to the livelihood of other cultures. It is safe to say that this movie is certainly on my favorites list.\"),\n",
       " (0,\n",
       "  \"This UK psychological thriller is known in the United States as CLOSURE. Exploitation of X-Files' Gillian Anderson, who plays an attractive middle aged businesswoman of substance named Alice. She must attend a business party and invites Adam(Danny Dyer), who just installed a security system for her, to be her escort. On the way home, speeding through the woods on a narrow lane, Alice's auto collides with a deer. After pulling the wounded animal off the road, the couple is savagely attacked by a drunken gang of thugs. Adam is beat to a pulp; Alice is gang raped and both are emotionally and physically devastated by the ruthless attack. When the identities of their attackers are discovered, Alice and Adam set out to exact revenge...brutal revenge. The couple at times find themselves at odds on how to deal with the ruthless attackers. Their final decision is to avenge with no mercy. Let there be no mistake, payback IS hell. Also in the cast: Anthony Calf, Ralph Brown, Francesca Fowler and Antony Byrne. Brutal violence, disturbing images, nudity and graphic rape.\"),\n",
       " (1,\n",
       "  \"The Blob is a classic 1950s B-movie sci-fi flick. You probably know the story: two teens (Steve McQueen & Aneta Corsaut) see a meteorite hit the ground, and when they go to look for it, they run into an old man with some weird...blob attached to his arm. They take him to the doctor's office, and then go to find out what happened. From there, the blob spreads, eating everyone in its path. The special effects are cheesy fun, as is the story. There are a lot of great touches, like the cop who plays chess over the radio with a cop in another district. It's no masterpiece, but it has a special place in its genre. Steve McQueen is very good. 8/10.\")]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=preprocess_data(\"../Data/aclImdb/train\")\n",
    "dataset[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer and tokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors=KeyedVectors.load_word2vec_format('../Data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_vectorize(dataset):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    vectorized_data = []\n",
    "    expected = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenizer.tokenize(sample[1])\n",
    "        sample_vecs = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                sample_vecs.append(word_vectors[token])\n",
    "            except KeyError:\n",
    "                pass  # No matching token in the Google w2v vocab\n",
    "\n",
    "        vectorized_data.append(sample_vecs)\n",
    "\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data=tokenize_and_vectorize(dataset)\n",
    "expected = []\n",
    "for sample in dataset:\n",
    "    expected.append(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from sklearn import model_selection\n",
    "\n",
    "print(len(vectorized_data))\n",
    "print(len(expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=model_selection.train_test_split(\n",
    "    vectorized_data, expected, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=400\n",
    "batch_size=32\n",
    "embedding_dims=300\n",
    "filters=250\n",
    "kernel_size=3\n",
    "hidden_dims=250\n",
    "epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_trunc(data, maxlen):\n",
    "    \"\"\" For a given dataset pad with zero vectors or truncate to maxlen \"\"\"\n",
    "    new_data = []\n",
    "\n",
    "    # Create a vector of 0's the length of our word vectors\n",
    "    zero_vector = []\n",
    "    for _ in range(len(data[0][0])):\n",
    "        zero_vector.append(0.0)\n",
    "\n",
    "    for sample in data:\n",
    "\n",
    "        if len(sample) > maxlen:\n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample) < maxlen:\n",
    "            temp = sample\n",
    "            additional_elems = maxlen - len(sample)\n",
    "            for _ in range(additional_elems):\n",
    "                temp.append(zero_vector)\n",
    "        else:\n",
    "            temp = sample\n",
    "        new_data.append(temp)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = pad_trunc(X_train, maxlen)\n",
    "X_test = pad_trunc(X_test, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_trunc(X_train, maxlen)\n",
    "X_test = pad_trunc(X_test, maxlen)\n",
    "\n",
    "X_train = np.reshape(X_train, (len(X_train), maxlen, embedding_dims))\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.reshape(X_test, (len(X_test), maxlen, embedding_dims))\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL\n",
    "model = Sequential()\n",
    "model.add(Conv1D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    padding='valid',\n",
    "    activation='relu',\n",
    "    strides=1,\n",
    "    input_shape=(maxlen, embedding_dims)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 325s 16ms/step - loss: 0.3998 - acc: 0.8077 - val_loss: 0.3360 - val_acc: 0.8586\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 359s 18ms/step - loss: 0.2300 - acc: 0.9075 - val_loss: 0.2801 - val_acc: 0.8872\n"
     ]
    }
   ],
   "source": [
    "#Max Pool\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "model_structure = model.to_json()\n",
    "with open(\"cnn_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "\n",
    "model.save_weights(\"cnn_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
